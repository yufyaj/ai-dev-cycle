#!/usr/bin/env python3
"""
ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Node.js (Jest/Vitest) ã¨ Python (pytest) ã®ä¸¡æ–¹ã‚’ã‚µãƒãƒ¼ãƒˆ
"""

import os
import sys
import json
import subprocess
from pathlib import Path
from typing import Dict, List, Tuple


def detect_project_type() -> List[str]:
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚¤ãƒ—ã‚’æ¤œå‡º"""
    project_types = []

    if Path('package.json').exists():
        project_types.append('nodejs')

    if Path('requirements.txt').exists() or Path('setup.py').exists() or Path('pyproject.toml').exists():
        project_types.append('python')

    return project_types


def run_nodejs_tests() -> Tuple[bool, str, Dict]:
    """Node.js ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
    print("ğŸ§ª Node.js ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œä¸­...")
    results = {
        'type': 'nodejs',
        'success': False,
        'tests_passed': 0,
        'tests_failed': 0,
        'coverage': 0
    }

    # package.json ã‚’èª­ã¿è¾¼ã¿
    with open('package.json', 'r') as f:
        package_data = json.load(f)

    scripts = package_data.get('scripts', {})

    # ãƒ†ã‚¹ãƒˆã‚³ãƒãƒ³ãƒ‰ã‚’ç‰¹å®š
    test_commands = []
    if 'test' in scripts:
        test_commands.append('npm test')
    if 'test:unit' in scripts:
        test_commands.append('npm run test:unit')
    if 'test:integration' in scripts:
        test_commands.append('npm run test:integration')
    if 'test:e2e' in scripts:
        test_commands.append('npm run test:e2e')

    if not test_commands:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§Jest/Vitestã‚’è©¦ã™
        if Path('node_modules/.bin/jest').exists():
            test_commands.append('npx jest --coverage')
        elif Path('node_modules/.bin/vitest').exists():
            test_commands.append('npx vitest run --coverage')
        else:
            return False, "ãƒ†ã‚¹ãƒˆã‚³ãƒãƒ³ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", results

    all_output = []
    all_success = True

    for cmd in test_commands:
        print(f"  å®Ÿè¡Œ: {cmd}")
        result = subprocess.run(
            cmd,
            shell=True,
            capture_output=True,
            text=True
        )

        all_output.append(f"=== {cmd} ===\n{result.stdout}\n{result.stderr}")
        if result.returncode != 0:
            all_success = False

        # ãƒ†ã‚¹ãƒˆçµæœã‚’ãƒ‘ãƒ¼ã‚¹ï¼ˆç°¡ç•¥åŒ–ï¼‰
        output = result.stdout + result.stderr
        if 'Tests:' in output or 'Test Suites:' in output:
            # Jestå½¢å¼ã®ãƒ‘ãƒ¼ã‚¹
            import re
            passed_match = re.search(r'(\d+) passed', output)
            failed_match = re.search(r'(\d+) failed', output)

            if passed_match:
                results['tests_passed'] += int(passed_match.group(1))
            if failed_match:
                results['tests_failed'] += int(failed_match.group(1))

        # ã‚«ãƒãƒ¬ãƒƒã‚¸æƒ…å ±ã‚’ãƒ‘ãƒ¼ã‚¹
        if 'Coverage' in output or 'Statements' in output:
            coverage_match = re.search(r'All files.*?(\d+\.?\d*)%', output)
            if coverage_match:
                results['coverage'] = float(coverage_match.group(1))

    results['success'] = all_success
    return all_success, '\n'.join(all_output), results


def run_python_tests() -> Tuple[bool, str, Dict]:
    """Python ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
    print("ğŸ§ª Python ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œä¸­...")
    results = {
        'type': 'python',
        'success': False,
        'tests_passed': 0,
        'tests_failed': 0,
        'coverage': 0
    }

    # pytest ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
    pytest_installed = subprocess.run(
        'python -m pytest --version',
        shell=True,
        capture_output=True,
        text=True
    ).returncode == 0

    if not pytest_installed:
        print("  pytest ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...")
        subprocess.run('pip install pytest pytest-cov', shell=True)

    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    test_dirs = []
    if Path('tests').exists():
        test_dirs.append('tests')
    if Path('test').exists():
        test_dirs.append('test')

    # srcãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®test_*.pyã‚‚æ¤œç´¢
    test_files = list(Path('.').rglob('test_*.py'))
    test_files.extend(list(Path('.').rglob('*_test.py')))

    if not test_dirs and not test_files:
        return True, "ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰", results

    # pytest å®Ÿè¡Œ
    cmd = 'python -m pytest'
    if test_dirs:
        cmd += ' ' + ' '.join(test_dirs)
    cmd += ' --cov --cov-report=term --cov-report=json -v'

    print(f"  å®Ÿè¡Œ: {cmd}")
    result = subprocess.run(
        cmd,
        shell=True,
        capture_output=True,
        text=True
    )

    output = result.stdout + result.stderr

    # ãƒ†ã‚¹ãƒˆçµæœã‚’ãƒ‘ãƒ¼ã‚¹
    import re
    # "5 passed, 2 failed" ã®ã‚ˆã†ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
    passed_match = re.search(r'(\d+) passed', output)
    failed_match = re.search(r'(\d+) failed', output)

    if passed_match:
        results['tests_passed'] = int(passed_match.group(1))
    if failed_match:
        results['tests_failed'] = int(failed_match.group(1))

    # ã‚«ãƒãƒ¬ãƒƒã‚¸æƒ…å ±ã‚’å–å¾—
    if Path('coverage.json').exists():
        with open('coverage.json', 'r') as f:
            cov_data = json.load(f)
            results['coverage'] = cov_data.get('totals', {}).get('percent_covered', 0)

    results['success'] = result.returncode == 0
    return result.returncode == 0, output, results


def generate_test_report(all_results: List[Dict]) -> None:
    """ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
    os.makedirs('out', exist_ok=True)

    report = {
        'timestamp': subprocess.run(
            'date -Iseconds',
            shell=True,
            capture_output=True,
            text=True
        ).stdout.strip(),
        'results': all_results,
        'summary': {
            'total_tests_passed': sum(r['tests_passed'] for r in all_results),
            'total_tests_failed': sum(r['tests_failed'] for r in all_results),
            'average_coverage': sum(r['coverage'] for r in all_results) / len(all_results) if all_results else 0,
            'all_passed': all(r['success'] for r in all_results)
        }
    }

    with open('out/test_report.json', 'w') as f:
        json.dump(report, f, indent=2)

    print("\nğŸ“Š ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆ:")
    print(f"  âœ… æˆåŠŸ: {report['summary']['total_tests_passed']}")
    print(f"  âŒ å¤±æ•—: {report['summary']['total_tests_failed']}")
    print(f"  ğŸ“ˆ ã‚«ãƒãƒ¬ãƒƒã‚¸: {report['summary']['average_coverage']:.1f}%")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸš€ å…¨ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¾ã™...")

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚¤ãƒ—ã‚’æ¤œå‡º
    project_types = detect_project_type()
    if not project_types:
        print("âš ï¸ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚¤ãƒ—ã‚’æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
        print("â„¹ï¸ ãƒ†ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ï¼ˆæˆåŠŸã¨ã—ã¦æ‰±ã„ã¾ã™ï¼‰")
        # outãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¨ãƒ€ãƒŸãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        os.makedirs('out', exist_ok=True)
        with open('out/test_results.log', 'w') as f:
            f.write("No tests found - skipping\n")
        # ä½•ã‚‚ãƒ†ã‚¹ãƒˆãŒãªã„å ´åˆã¯æˆåŠŸã¨ã—ã¦æ‰±ã†
        sys.exit(0)

    all_results = []
    all_outputs = []
    overall_success = True

    # å„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚¤ãƒ—ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
    if 'nodejs' in project_types:
        success, output, results = run_nodejs_tests()
        all_results.append(results)
        all_outputs.append(output)
        if not success:
            overall_success = False

    if 'python' in project_types:
        success, output, results = run_python_tests()
        all_results.append(results)
        all_outputs.append(output)
        if not success:
            overall_success = False

    # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    os.makedirs('out', exist_ok=True)
    with open('out/test_results.log', 'w') as f:
        f.write('\n'.join(all_outputs))

    # ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
    generate_test_report(all_results)

    # çµ‚äº†ã‚³ãƒ¼ãƒ‰
    if overall_success:
        print("\nâœ… ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆã«æˆåŠŸã—ã¾ã—ãŸï¼")
        sys.exit(0)
    else:
        print("\nâŒ ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ")
        sys.exit(1)


if __name__ == '__main__':
    main()